{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d32e2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cu126\n",
      "Thu Dec  4 18:03:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   62C    P0             28W /   70W |     362MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36136913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(t):\n",
    "\tprint(\"\\n--------------------------------\")\n",
    "\tprint(f'{t} shape={t.shape} dtype={t.dtype} device={t.device} ndim={t.ndim}')\n",
    "\tprint(t)\n",
    "\tprint(t.T)\n",
    "\n",
    "\tprint(t.sum())\n",
    "\tprint(t.sum(dim=0))\n",
    "\tprint(t.sum(dim=1))\n",
    "\n",
    "\tprint(t.mean())\n",
    "\tprint(t.mean(dim=0))\n",
    "\tprint(t.mean(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9ef84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "tensor([[[1., 2., 3.],\n",
      "         [4., 5., 6.]]]) shape=torch.Size([1, 2, 3]) dtype=torch.float32 device=cpu ndim=3\n",
      "tensor([[[1., 2., 3.],\n",
      "         [4., 5., 6.]]])\n",
      "tensor([[[1.],\n",
      "         [4.]],\n",
      "\n",
      "        [[2.],\n",
      "         [5.]],\n",
      "\n",
      "        [[3.],\n",
      "         [6.]]])\n",
      "tensor(21.)\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[5., 7., 9.]])\n",
      "tensor(3.5000)\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[2.5000, 3.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(\n",
    "\t[\n",
    "\t\t[\n",
    "\t\t\t[1.0,2.0,3.0], \n",
    "\t\t\t[4.0,5.0,6.0]\n",
    "\t\t]\n",
    "\t]\n",
    ")\n",
    "info(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd27079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) shape=torch.Size([2, 3]) dtype=torch.float32 device=cpu ndim=2\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "tensor(21.)\n",
      "tensor([5., 7., 9.])\n",
      "tensor([ 6., 15.])\n",
      "tensor(3.5000)\n",
      "tensor([2.5000, 3.5000, 4.5000])\n",
      "tensor([2., 5.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t = torch.tensor(\n",
    "\t[\n",
    "\t\t[1.0,2.0,3.0], \n",
    "\t\t[4.0,5.0,6.0]\n",
    "\t]\n",
    ")\n",
    "info(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9262ab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([1, 4, 9])\n",
      "tensor(14)\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "one_to_ten = torch.arange(1, 11)\n",
    "print(one_to_ten)\n",
    "\n",
    "t = torch.tensor([1,2,3])\n",
    "print(t * t)\n",
    "print(t.matmul(t))\n",
    "print(t @ t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190d657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
