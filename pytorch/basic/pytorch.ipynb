{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36738f7a",
   "metadata": {},
   "source": [
    "* https://blog.ezyang.com/2019/05/pytorch-internals/\n",
    "* https://web.mit.edu/~ezyang/Public/pytorch-internals.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d32e2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36136913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(t):\n",
    "\tprint(\"\\n--------------------------------\")\n",
    "\tprint(f'{t} \\nshape={t.shape} dtype={t.dtype} device={t.device} ndim={t.ndim}\\n')\n",
    "\n",
    "\tfor i in range(t.ndim):\n",
    "\t\tprint(f't.sum(dim={i}): {t.sum(dim=i)}') # Sum of the values\n",
    "\t\tprint(f'mean dim={i}: {t.mean(dim=i)}') # Find the mean value\n",
    "\t\tprint(f\"t.max(dim={i}): {t.max(dim=i)}\") # Find the maximum value\n",
    "\t\tprint(f\"t.min(dim={i}): {t.min(dim=i)}\") # Find the minimum value\n",
    "\t\tprint(f\"t.argmax(dim={i}): {t.argmax(dim=i)}\") # Find the index of the maximum value\n",
    "\t\tprint(f\"t.argmin(dim={i}): {t.argmin(dim=i)}\") # Find the index of the minimum value\n",
    "\t\tprint(f\"t.std(dim={i}): {t.std(dim=i)}\") # Standard deviation\n",
    "\t\tprint(f\"t.var(dim=-1): {t.var(dim=-1)}\") # Variance\n",
    "\t\tprint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd27079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) \n",
      "shape=torch.Size([2, 3]) dtype=torch.float32 device=cpu ndim=2\n",
      "\n",
      "t.sum(dim=0): tensor([5., 7., 9.])\n",
      "mean dim=0: tensor([2.5000, 3.5000, 4.5000])\n",
      "t.max(dim=0): torch.return_types.max(\n",
      "values=tensor([4., 5., 6.]),\n",
      "indices=tensor([1, 1, 1]))\n",
      "t.min(dim=0): torch.return_types.min(\n",
      "values=tensor([1., 2., 3.]),\n",
      "indices=tensor([0, 0, 0]))\n",
      "t.argmax(dim=0): tensor([1, 1, 1])\n",
      "t.argmin(dim=0): tensor([0, 0, 0])\n",
      "t.std(dim=0): tensor([2.1213, 2.1213, 2.1213])\n",
      "t.var(dim=-1): tensor([1., 1.])\n",
      "\n",
      "t.sum(dim=1): tensor([ 6., 15.])\n",
      "mean dim=1: tensor([2., 5.])\n",
      "t.max(dim=1): torch.return_types.max(\n",
      "values=tensor([3., 6.]),\n",
      "indices=tensor([2, 2]))\n",
      "t.min(dim=1): torch.return_types.min(\n",
      "values=tensor([1., 4.]),\n",
      "indices=tensor([0, 0]))\n",
      "t.argmax(dim=1): tensor([2, 2])\n",
      "t.argmin(dim=1): tensor([0, 0])\n",
      "t.std(dim=1): tensor([1., 1.])\n",
      "t.var(dim=-1): tensor([1., 1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "info(torch.tensor(\n",
    "\t[\n",
    "\t\t[1.0,2.0,3.0], \n",
    "\t\t[4.0,5.0,6.0]\n",
    "\t]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58759d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "tensor([[[ 1.,  2.,  3.,  4.],\n",
      "         [ 5.,  6.,  7.,  8.],\n",
      "         [ 9., 10., 11., 12.]],\n",
      "\n",
      "        [[13., 14., 15., 16.],\n",
      "         [17., 18., 19., 20.],\n",
      "         [21., 22., 23., 24.]]]) \n",
      "shape=torch.Size([2, 3, 4]) dtype=torch.float32 device=cpu ndim=3\n",
      "\n",
      "t.sum(dim=0): tensor([[14., 16., 18., 20.],\n",
      "        [22., 24., 26., 28.],\n",
      "        [30., 32., 34., 36.]])\n",
      "mean dim=0: tensor([[ 7.,  8.,  9., 10.],\n",
      "        [11., 12., 13., 14.],\n",
      "        [15., 16., 17., 18.]])\n",
      "t.max(dim=0): torch.return_types.max(\n",
      "values=tensor([[13., 14., 15., 16.],\n",
      "        [17., 18., 19., 20.],\n",
      "        [21., 22., 23., 24.]]),\n",
      "indices=tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]]))\n",
      "t.min(dim=0): torch.return_types.min(\n",
      "values=tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]]),\n",
      "indices=tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]))\n",
      "t.argmax(dim=0): tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n",
      "t.argmin(dim=0): tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n",
      "t.std(dim=0): tensor([[8.4853, 8.4853, 8.4853, 8.4853],\n",
      "        [8.4853, 8.4853, 8.4853, 8.4853],\n",
      "        [8.4853, 8.4853, 8.4853, 8.4853]])\n",
      "t.var(dim=-1): tensor([[1.6667, 1.6667, 1.6667],\n",
      "        [1.6667, 1.6667, 1.6667]])\n",
      "\n",
      "t.sum(dim=1): tensor([[15., 18., 21., 24.],\n",
      "        [51., 54., 57., 60.]])\n",
      "mean dim=1: tensor([[ 5.,  6.,  7.,  8.],\n",
      "        [17., 18., 19., 20.]])\n",
      "t.max(dim=1): torch.return_types.max(\n",
      "values=tensor([[ 9., 10., 11., 12.],\n",
      "        [21., 22., 23., 24.]]),\n",
      "indices=tensor([[2, 2, 2, 2],\n",
      "        [2, 2, 2, 2]]))\n",
      "t.min(dim=1): torch.return_types.min(\n",
      "values=tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [13., 14., 15., 16.]]),\n",
      "indices=tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]))\n",
      "t.argmax(dim=1): tensor([[2, 2, 2, 2],\n",
      "        [2, 2, 2, 2]])\n",
      "t.argmin(dim=1): tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n",
      "t.std(dim=1): tensor([[4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.]])\n",
      "t.var(dim=-1): tensor([[1.6667, 1.6667, 1.6667],\n",
      "        [1.6667, 1.6667, 1.6667]])\n",
      "\n",
      "t.sum(dim=2): tensor([[10., 26., 42.],\n",
      "        [58., 74., 90.]])\n",
      "mean dim=2: tensor([[ 2.5000,  6.5000, 10.5000],\n",
      "        [14.5000, 18.5000, 22.5000]])\n",
      "t.max(dim=2): torch.return_types.max(\n",
      "values=tensor([[ 4.,  8., 12.],\n",
      "        [16., 20., 24.]]),\n",
      "indices=tensor([[3, 3, 3],\n",
      "        [3, 3, 3]]))\n",
      "t.min(dim=2): torch.return_types.min(\n",
      "values=tensor([[ 1.,  5.,  9.],\n",
      "        [13., 17., 21.]]),\n",
      "indices=tensor([[0, 0, 0],\n",
      "        [0, 0, 0]]))\n",
      "t.argmax(dim=2): tensor([[3, 3, 3],\n",
      "        [3, 3, 3]])\n",
      "t.argmin(dim=2): tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "t.std(dim=2): tensor([[1.2910, 1.2910, 1.2910],\n",
      "        [1.2910, 1.2910, 1.2910]])\n",
      "t.var(dim=-1): tensor([[1.6667, 1.6667, 1.6667],\n",
      "        [1.6667, 1.6667, 1.6667]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info(torch.tensor(\n",
    "\t[\n",
    "\t\t[\n",
    "\t\t\t[1.0,2.0,3.0,4.0], \n",
    "\t\t\t[5.0,6.0,7.0,8.0],\n",
    "\t\t\t[9.0,10.0,11.0,12.0], \n",
    "\t\t],\n",
    "\t\t[\n",
    "\t\t\t[13.0,14.0,15.0,16.0],\n",
    "\t\t\t[17.0,18.0,19.0,20.0],\n",
    "\t\t\t[21.0,22.0,23.0,24.0],\n",
    "\t\t]\n",
    "\t]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9262ab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([1, 4, 9])\n",
      "tensor(14)\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "one_to_ten = torch.arange(1, 11)\n",
    "print(one_to_ten)\n",
    "\n",
    "t = torch.tensor([1,2,3])\n",
    "print(t * t)\n",
    "print(t.matmul(t))\n",
    "print(t @ t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07038f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.unsqueeze(0): tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "t.unsqueeze(1): tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]])\n",
      "t.unsqueeze(-1): tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]])\n",
      "--------------------------------\n",
      "t.view(6): tensor([1, 2, 3, 4, 5, 6])\n",
      "--------------------------------\n",
      "t.permute(1, 0): tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "t.transpose(0, 1): tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "--------------------------------\n",
      "torch.stack((t, t)): tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "--------------------------------\n",
      "t.squeeze(): tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "t.unsqueeze(0).squeeze(): tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "--------------------------------\n",
      "t.reshape(2, 3): tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "t.reshape(6): tensor([1, 2, 3, 4, 5, 6])\n",
      "--------------------------------\n",
      "t.permute(1, 0): tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "t.transpose(0, 1): tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "--------------------------------\n",
      "t.view(2, 3): tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "t.view(6): tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Stack : concatenate tensors along a new dimension\t\n",
    "# Squeeze : remove all dimensions of size 1\n",
    "# Unsqueeze : add a new dimension of size 1\n",
    "# Reshape : change the shape of the tensor\n",
    "# Permute : permute the dimensions of the tensor\n",
    "# View : reshape tensor to different shape\n",
    "# Transpose : swap two dimensions of the tensor\n",
    "\n",
    "t = torch.tensor([\n",
    "\t[1,2,3],\n",
    "\t[4,5,6]\n",
    "])\n",
    "print(f\"t.unsqueeze(0): {t.unsqueeze(0)}\")\n",
    "print(f\"t.unsqueeze(1): {t.unsqueeze(1)}\")\n",
    "print(f\"t.unsqueeze(-1): {t.unsqueeze(-1)}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"t.view(6): {t.view(6)}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"t.permute(1, 0): {t.permute(1, 0)}\")\n",
    "print(f\"t.transpose(0, 1): {t.transpose(0, 1)}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"torch.stack((t, t)): {torch.stack((t, t))}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"t.squeeze(): {t.squeeze()}\")\n",
    "print(f\"t.unsqueeze(0).squeeze(): {t.unsqueeze(0).squeeze()}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"t.reshape(2, 3): {t.reshape(2, 3)}\")\n",
    "print(f\"t.reshape(6): {t.reshape(6)}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"t.permute(1, 0): {t.permute(1, 0)}\")\n",
    "print(f\"t.transpose(0, 1): {t.transpose(0, 1)}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"t.view(2, 3): {t.view(2, 3)}\")\n",
    "print(f\"t.view(6): {t.view(6)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8140fae",
   "metadata": {},
   "source": [
    "## Broadcasting in PyTorch/NumPy\n",
    "\n",
    "https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "\n",
    "Broadcasting lets you do operations on tensors with different shapes without explicit copying.\n",
    "The Rules\n",
    "Two tensors are broadcastable if, comparing dimensions right-to-left:\n",
    "Dimensions are equal, OR\n",
    "One of them is 1, OR\n",
    "One of them doesn't exist (missing)\n",
    "\n",
    "Compare shapes RIGHT to LEFT:\n",
    "A: [8, 1, 6, 1]\n",
    "B:    [7, 1, 5]\n",
    "     ↑  ↑  ↑  ↑\n",
    "     8  7  6  5  → Result shape: [8, 7, 6, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0527f193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 22, 33],\n",
      "        [14, 25, 36]])\n",
      "tensor([[11, 12, 13],\n",
      "        [24, 25, 26]])\n"
     ]
    }
   ],
   "source": [
    "# Simple: scalar broadcasts to any shape\n",
    "a = torch.tensor([[1, 2], [3, 4]])  # [2, 2]\n",
    "b = torch.tensor(10)                 # scalar []\n",
    "a + b  # [[11, 12], [13, 14]]\n",
    "\n",
    "# Row broadcasts across rows\n",
    "a = torch.tensor([\n",
    "\t[1, 2, 3],\n",
    "\t[4, 5, 6]])        # [2, 3]\n",
    "b = torch.tensor([10, 20, 30])       # [3]\n",
    "\n",
    "print(a + b)\n",
    "\n",
    "# Column broadcasts across columns (need shape [2, 1])\n",
    "b = torch.tensor([[10], [20]])       # [2, 1]\n",
    "print(a + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d7eabc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 21, 31],\n",
       "        [12, 22, 32],\n",
       "        [13, 23, 33]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1],    # shape [3, 1]\n",
    "                  [2],\n",
    "                  [3]])\n",
    "\n",
    "b = torch.tensor([10, 20, 30])  # shape [3]\n",
    "\n",
    "# Step 1: Align shapes right-to-left\n",
    "# a: [3, 1]\n",
    "# b:    [3]  → treated as [1, 3]\n",
    "\n",
    "# Step 2: Expand dims of size 1\n",
    "# a: [3, 1] → [[1, 1, 1],    (row repeated 3x)\n",
    "#              [2, 2, 2],\n",
    "#              [3, 3, 3]]\n",
    "#\n",
    "# b: [1, 3] → [[10, 20, 30], (col repeated 3x)\n",
    "#              [10, 20, 30],\n",
    "#              [10, 20, 30]]\n",
    "\n",
    "# Step 3: Element-wise operation\n",
    "a + b  # [[11, 21, 31],\n",
    "       #  [12, 22, 32],\n",
    "       #  [13, 23, 33]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda4e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalize columns (subtract mean per column)\n",
    "x = torch.randn(100, 5)          # [100, 5]\n",
    "mean = x.mean(dim=0)             # [5]\n",
    "x_centered = x - mean            # broadcasts [5] → [100, 5]\n",
    "\n",
    "# 2. Scale rows differently\n",
    "x = torch.randn(100, 5)              # [100, 5]\n",
    "weights = torch.rand(100, 1)         # [100, 1] - random weights per row\n",
    "x_scaled = x * weights               # broadcasts [100,1] → [100, 5]\n",
    "\n",
    "# Or create specific weights:\n",
    "weights = torch.linspace(0.1, 1.0, 100).unsqueeze(1)  # [100, 1]\n",
    "\n",
    "# 3. Outer product\n",
    "a = torch.tensor([1, 2, 3])      # [3]\n",
    "b = torch.tensor([10, 20])       # [2]\n",
    "outer = a[:, None] * b[None, :]  # [3,1] * [1,2] → [3, 2]\n",
    "# [[10, 20],\n",
    "#  [20, 40],\n",
    "#  [30, 60]]\n",
    "\n",
    "# 4. Pairwise distances\n",
    "x = torch.randn(100, 3)          # 100 points in 3D\n",
    "# x[:, None, :] shape: [100, 1, 3]\n",
    "# x[None, :, :] shape: [1, 100, 3]\n",
    "diff = x[:, None, :] - x[None, :, :]  # [100, 100, 3]\n",
    "dist = (diff ** 2).sum(-1).sqrt()     # [100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94c9d73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ks/_614mn9d3c53zg_y00d9md840000gn/T/ipykernel_20488/475401501.py:5: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  expanded.storage().size()     # still only 3 elements in memory!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broadcasting doesn't copy data - it's a view trick. \n",
    "# The tensor acts as if it's larger but uses the same memory:\n",
    "a = torch.tensor([1, 2, 3])\n",
    "expanded = a.expand(1000, 3)  # \"looks\" like [1000, 3]\n",
    "expanded.storage().size()     # still only 3 elements in memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4fe9f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]]])\n",
      "18\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "print(a)\n",
    "print(a.view(2, 3, 3))\n",
    "print(a.storage().size())\n",
    "print(a.storage().dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b099c397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
